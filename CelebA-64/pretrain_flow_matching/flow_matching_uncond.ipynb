{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdyn\n",
        "!pip install torchcfm"
      ],
      "metadata": {
        "id": "wcIDMdgMFb69"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ow7-tH7hha2f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ToKredW6FMw1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.datasets import make_moons\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import Sampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchcfm.models.unet.unet import UNetModelWrapper\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchcfm.models.unet import UNetModel\n",
        "import torchdiffeq\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import ToPILImage\n",
        "from torchvision import datasets, transforms\n",
        "import gc\n",
        "import copy\n",
        "from tqdm import trange\n",
        "\n",
        "from torchdyn.core import NeuralODE\n",
        "from torchvision.utils import make_grid, save_image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "He4tVE9dFQvk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "#!unzip -q \"/content/drive/MyDrive/ml_project/data.zip\" -d \"/content\"\n",
        "#!cp /content/drive/MyDrive/ml_project/fm_celeba_step_49500.pth /content/\n"
      ],
      "metadata": {
        "id": "vdBscC0Jks-i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "LR = 2e-4\n",
        "TOTAL_STEPS = 40000\n",
        "GRAD_CLIP = 1.0\n",
        "WARMUP = 5000\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4\n",
        "SAVE_STEP = 2000\n",
        "\n",
        "print(\"Current device:\", device)"
      ],
      "metadata": {
        "id": "Nm469gY4Fiuq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infiniteloop(dataloader):\n",
        "    \"\"\"Creates an infinite iterator over a given dataloader.\"\"\"\n",
        "    while True:\n",
        "        for x, _ in iter(dataloader):  # For CelebA, second output is attributes; ignore if not used\n",
        "            yield x\n",
        "\n",
        "def warmup_lr(step, WARMUP=5000):\n",
        "    \"\"\"Simple warmup schedule: scales LR from 0 to initial LR over first WARMUP steps.\"\"\"\n",
        "    return min(step, WARMUP) / WARMUP\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    \"\"\"Sets random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # For exact reproducibility (slower)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import os\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_samples(model,\n",
        "                     savedir=\"./results/\",\n",
        "                     step_=0,\n",
        "                     total_steps=100,\n",
        "                     net_=\"normal\",\n",
        "                     plot=False):\n",
        "    \"\"\"\n",
        "    Save and optionally plot 32 generated images (4 x 8) for a quick qualitative check.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # copy the trained model to avoid messing up BN stats (if any)\n",
        "    model_ = copy.deepcopy(model)\n",
        "\n",
        "    node_ = NeuralODE(model_, solver=\"euler\", sensitivity=\"adjoint\").to(device)\n",
        "    # sample random noise\n",
        "    z = torch.randn(32, 3, 64, 64, device=device)\n",
        "\n",
        "    # Evaluate trajectory from noise z from t=0 to t=1\n",
        "    t_span = torch.linspace(0, 1, total_steps, device=device)\n",
        "    traj = node_.trajectory(z, t_span)  # shape: [total_steps, 32, 3, 64, 64]\n",
        "    # final state\n",
        "    x_gen = traj[-1, :].clip(-1, 1)\n",
        "    x_gen = x_gen / 2 + 0.5  # move from [-1,1] to [0,1]\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(savedir, exist_ok=True)\n",
        "\n",
        "    # Save image grid\n",
        "    save_image(\n",
        "        x_gen,\n",
        "        f\"{savedir}/{net_}_generated_FM_images_step_{step_}_total_{total_steps}.png\",\n",
        "        nrow=8\n",
        "    )\n",
        "\n",
        "    if plot:\n",
        "        grid = make_grid(x_gen, nrow=8)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Generated Samples: {net_} | total_steps={total_steps}\")\n",
        "        plt.show()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def ema(source, target, decay=0.9999):\n",
        "    source_dict = source.state_dict()\n",
        "    target_dict = target.state_dict()\n",
        "    for key in source_dict.keys():\n",
        "        target_dict[key].data.copy_(\n",
        "            target_dict[key].data * decay + source_dict[key].data * (1 - decay)\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "Wt4apZMaFoDm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Setup\n",
        "############################\n",
        "def get_celeba_dataloader(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.CenterCrop(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "    celeba_train = datasets.CelebA(\n",
        "        root='./data',\n",
        "        split='train',\n",
        "        transform=transform,\n",
        "        download=False\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        celeba_train,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        drop_last=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return train_loader\n",
        "\n",
        "dataloader = get_celeba_dataloader(64)"
      ],
      "metadata": {
        "id": "KXVAT_XNFpi4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "net_model = UNetModelWrapper(\n",
        "        dim=(3, 64, 64),\n",
        "        num_res_blocks=2,\n",
        "        num_channels=128,\n",
        "        channel_mult=[1, 2, 2, 4],\n",
        "        num_heads=4,\n",
        "        num_head_channels=64,\n",
        "        attention_resolutions=\"16\",  # or \"16,8\" as you prefer\n",
        "        dropout=0.05,\n",
        "    ).to(device)\n",
        "\n",
        "    # 3) Create EMA copy\n",
        "ema_model = copy.deepcopy(net_model)\n",
        "\n",
        "    # 6) Print model size\n",
        "model_size = sum(p.numel() for p in net_model.parameters())\n",
        "print(\"Model params: %.2f M\" % (model_size / 1024 / 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSrLCvGbFtOF",
        "outputId": "f57ec96c-9372-42aa-d833-9c07e58ce9e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model params: 65.61 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "opt"
      ],
      "metadata": {
        "id": "0gHoq2t1G6j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(net_model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda s: warmup_lr(s))\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "CHECKPOINT_PATH = \"./checkpoints/fm_celeba_step_49500.pth\"\n",
        "# If resuming, load the checkpoint:\n",
        "start_step = 0\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "    net_model.load_state_dict(checkpoint[\"net_model\"])\n",
        "    ema_model.load_state_dict(checkpoint[\"ema_model\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optim\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"sched\"])\n",
        "    start_step = checkpoint[\"step\"]\n",
        "    print(f\"Resumed training from step {start_step}\")\n",
        "else:\n",
        "    print(\"No checkpoint found, starting training from scratch.\")\n",
        "\n",
        "# If you want to resume the wandb run, supply the previous run id or resume=\"allow\"\n",
        "wandb.init(project=\"Celeba FM Grad\", resume=\"must\", id=\"lfusdxyf\")\n",
        "\n",
        "celeba_loader = get_celeba_dataloader(batch_size=BATCH_SIZE)\n",
        "data_loop = infiniteloop(celeba_loader)"
      ],
      "metadata": {
        "id": "KIH3BGKbFw_H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = trange(start_step, TOTAL_STEPS+start_step, desc=\"FlowMatching\", dynamic_ncols=True)\n",
        "for step in pbar:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Grab a batch of real images\n",
        "    x_1 = next(data_loop).to(device)  # shape: (B, 3, 64, 64)\n",
        "    x_0 = torch.randn_like(x_1)        # shape: (B, 3, 64, 64)\n",
        "\n",
        "    B = x_1.size(0)\n",
        "    t = torch.rand((B, 1), device=device).view(B, 1, 1, 1)\n",
        "    x_t = t * x_1 + (1 - t) * x_0\n",
        "    v_target = x_1 - x_0\n",
        "\n",
        "    t_flat = t.squeeze()  # shape: (B,)\n",
        "    v_predict = net_model(t_flat, x_t)\n",
        "    loss = loss_fn(v_predict, v_target)\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(net_model.parameters(), GRAD_CLIP)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    ema(net_model, ema_model)\n",
        "\n",
        "    wandb.log({\"train_loss\": loss.item(), \"step\": step})\n",
        "    pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    if SAVE_STEP > 0 and step > 0 and (step % SAVE_STEP == 0):\n",
        "        # Generate samples using your generate_samples function\n",
        "        generate_samples(net_model,\n",
        "                         savedir=\"./checkpoints/img/normal/\",\n",
        "                         step_=step,\n",
        "                         total_steps=100,\n",
        "                         net_=\"normal\")\n",
        "        generate_samples(ema_model,\n",
        "                         savedir=\"./checkpoints/img/ema/\",\n",
        "                         step_=step,\n",
        "                         total_steps=100,\n",
        "                         net_=\"ema\")\n",
        "\n",
        "        ckpt_path = f\"./checkpoints/fm_celeba_step_{step}.pth\"\n",
        "        torch.save({\n",
        "            \"net_model\": net_model.state_dict(),\n",
        "            \"ema_model\": ema_model.state_dict(),\n",
        "            \"sched\": scheduler.state_dict(),\n",
        "            \"optim\": optimizer.state_dict(),\n",
        "            \"step\": step,\n",
        "        }, ckpt_path)\n",
        "        wandb.save(ckpt_path)\n",
        "\n",
        "print(\"Training completed!\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "Idxnnm_iG72M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_samples(net_model,\n",
        "                         savedir=\"./checkpoints/img/normal/\",\n",
        "                         step_=step,\n",
        "                         total_steps=100,\n",
        "                         net_=\"normal\", plot = True)\n",
        "generate_samples(ema_model,\n",
        "                         savedir=\"./checkpoints/img/ema/\",\n",
        "                         step_=step,\n",
        "                         total_steps=100,\n",
        "                         net_=\"ema\", plot = True)"
      ],
      "metadata": {
        "id": "ID-hJJAErHLv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckpt_path = f\"./checkpoints/fm_celeba_step_{step}.pth\"\n",
        "#         torch.save({\n",
        "#             \"net_model\": net_model.state_dict(),\n",
        "#             \"ema_model\": ema_model.state_dict(),\n",
        "#             \"sched\": scheduler.state_dict(),\n",
        "#             \"optim\": optimizer.state_dict(),\n",
        "#             \"step\": step,\n",
        "#         }, ckpt_path)"
      ],
      "metadata": {
        "id": "JE81Xz2tG8kj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flow Generator Matching"
      ],
      "metadata": {
        "id": "uV-nghZO71Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchcfm.models.unet import UNetModel\n",
        "import torchdiffeq\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "from torchdiffeq import odeint"
      ],
      "metadata": {
        "id": "o8uB7hkU73Nh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class UnconditionalFlowLoss:\n",
        "\n",
        "    def __init__(self, sigma_min: float = 0.001):\n",
        "        super().__init__()\n",
        "        self.sigma_min = sigma_min\n",
        "        self.epsilon = 1e-5\n",
        "        self.device = device\n",
        "\n",
        "    def psi_t(self, x: torch.Tensor, x_1: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Linear interpolation between x0 -> x1 at times t in [0,1].\n",
        "        \"\"\"\n",
        "        # Reshape t so it can broadcast over HxW as well\n",
        "        while t.dim() < x.dim():\n",
        "            t = t[..., None]\n",
        "        # Interpolate from x0 to x1\n",
        "        return (1 - (1 - self.sigma_min) * t) * x + t * x_1\n",
        "\n",
        "    def loss_flow_matching(\n",
        "        self,\n",
        "        Online_v_t: nn.Module,\n",
        "        Pretrained_v_t: nn.Module,\n",
        "        Generator: nn.Module,\n",
        "        batch_size: int = 10,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Trains the 'Online_v_t' to replicate the known pretrained vector field\n",
        "        along the trajectory induced by the current Generator in [t=0..1].\n",
        "        \"\"\"\n",
        "        t = (torch.rand(1, device=self.device) + torch.arange(10 * batch_size, device=self.device) / (10 * batch_size)) % (1 - self.epsilon)\n",
        "        t = t[:, None]\n",
        "        t_steps = torch.linspace(0, 1, 5, device=self.device)  5 means 4 steps => multistep, change to 2 if u need 1 step\n",
        "        #class_condition = torch.tensor([x for x in range(10)] * batch_size, device=self.device)\n",
        "\n",
        "        z = torch.randn(10 * batch_size, 3, 64, 64, device=self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            traj = torchdiffeq.odeint(\n",
        "                lambda _t, _x: Generator(_t, _x),\n",
        "                z,\n",
        "                t_steps,\n",
        "                atol=1e-4,\n",
        "                rtol=1e-4,\n",
        "                method=\"euler\",\n",
        "            )\n",
        "\n",
        "        x_0 = traj[-1]\n",
        "        psi_t = self.psi_t(z, x_0, t)\n",
        "\n",
        "        d_psi = x_0 - (1 - self.sigma_min) * z\n",
        "        online_train = Online_v_t(t[:, 0], psi_t)\n",
        "\n",
        "        loss_flow_matching = torch.mean((online_train - d_psi) ** 2)\n",
        "\n",
        "        # Free up GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return loss_flow_matching\n",
        "\n",
        "    def loss_generator_matching(\n",
        "        self,\n",
        "        Online_v_t: nn.Module,\n",
        "        Pretrained_v_t: nn.Module,\n",
        "        Generator: nn.Module,\n",
        "        batch_size: int = 10,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Given the current Online_v_t, train the generator so that\n",
        "        G(z) matches the final sample we'd get by multi-step integration\n",
        "        of Pretrained_v_t from t=0..1 starting at z.\n",
        "        \"\"\"\n",
        "        t = (torch.rand(1, device=self.device) + torch.arange(10 * batch_size, device=self.device) / (10 * batch_size)) % (1 - self.epsilon)\n",
        "        t = t[:, None]\n",
        "        t_steps = torch.linspace(0, 1, 5, device=self.device) # 5 means 4 steps => multistep, change to 2 if u need 1 step\n",
        "        #class_condition = torch.tensor([x for x in range(10)] * batch_size, device=self.device)\n",
        "\n",
        "        z = torch.randn(10 * batch_size, 3, 64, 64, device=self.device)\n",
        "\n",
        "        traj = torchdiffeq.odeint(\n",
        "            lambda _t, _x: Generator(_t, _x),\n",
        "            z,\n",
        "            t_steps,\n",
        "            atol=1e-4,\n",
        "            rtol=1e-4,\n",
        "            method=\"euler\",\n",
        "        )\n",
        "\n",
        "        x_0 = traj[-1]\n",
        "\n",
        "        psi_t = self.psi_t(z, x_0, t)\n",
        "        d_psi = x_0 - (1 - self.sigma_min) * z\n",
        "\n",
        "        pre_train = Pretrained_v_t(t[:, 0], psi_t)\n",
        "        online_train = Online_v_t(t[:, 0], psi_t)\n",
        "\n",
        "        l1 = torch.mean((pre_train - online_train) ** 2)\n",
        "        l2 = torch.mean(2 * ((pre_train - online_train) * (online_train - d_psi)))\n",
        "\n",
        "        # Free up GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return l1 + l2, x_0"
      ],
      "metadata": {
        "id": "AGLYedzP8DEC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTOslkK08YCS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "device = 'cuda'\n",
        "checkpoint = torch.load(\"./checkpoints/fm_celeba_step_88000.pth\")\n",
        "\n",
        "state_dict_normal = checkpoint[\"net_model\"]\n",
        "state_dict_ema = checkpoint[\"ema_model\"]\n",
        "\n",
        "# net_model = UNetModelWrapper(\n",
        "#         dim=(3, 64, 64),\n",
        "#         num_res_blocks=2,\n",
        "#         num_channels=128,\n",
        "#         channel_mult=[1, 2, 2, 4],\n",
        "#         num_heads=4,\n",
        "#         num_head_channels=64,\n",
        "#         attention_resolutions=\"16\",  # or \"16,8\" as you prefer\n",
        "#         dropout=0.05,\n",
        "#     ).to(device)\n",
        "\n",
        "    # 3) Create EMA copy\n",
        "#ema_model = copy.deepcopy(net_model)\n",
        "\n",
        "#net_model.load_state_dict(state_dict_normal)\n",
        "ema_model.load_state_dict(state_dict_ema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "molCVGKz8EbH",
        "outputId": "72392133-9607-448c-a1b1-2d25fc6a74f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4a35f87428b2>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"./checkpoints/fm_celeba_step_88000.pth\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pretrained_v_t = UNetModelWrapper(\n",
        "        dim=(3, 64, 64),\n",
        "        num_res_blocks=2,\n",
        "        num_channels=128,\n",
        "        channel_mult=[1, 2, 2, 4],\n",
        "        num_heads=4,\n",
        "        num_head_channels=64,\n",
        "        attention_resolutions=\"16\",  # or \"16,8\" as you prefer\n",
        "        dropout=0.05,\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "Pretrained_v_t = copy.deepcopy(ema_model)  # net_model from your snippet\n",
        "Pretrained_v_t.eval()\n",
        "\n",
        "# Online_v_t: same dimension as your pretrained vector field\n",
        "Online_v_t = copy.deepcopy(Pretrained_v_t)\n",
        "\n",
        "Generator = UNetModelWrapper(\n",
        "        dim=(3, 64, 64),\n",
        "        num_res_blocks=2,\n",
        "        num_channels=64,\n",
        "        channel_mult=[1, 2, 2, 2],\n",
        "        num_heads=4,\n",
        "        num_head_channels=32,\n",
        "        attention_resolutions=\"16\",  # or \"16,8\" as you prefer\n",
        "        dropout=0.00,\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "for p in Pretrained_v_t.parameters():\n",
        "    p.requires_grad = False\n",
        "Pretrained_v_t.eval()\n",
        "\n",
        "\n",
        "model_size = sum(p.numel() for p in Generator.parameters())\n",
        "print(\"Generator model params: %.2f M\" % (model_size / 1024 / 1024))\n",
        "\n",
        "model_size_pretrain = sum(p.numel() for p in Pretrained_v_t.parameters())\n",
        "print(\"Original FM model params: %.2f M\" % (model_size_pretrain / 1024 / 1024))\n",
        "\n",
        "model_size_online = sum(p.numel() for p in Online_v_t.parameters())\n",
        "print(\"Online FM model params: %.2f M\" % (model_size_online / 1024 / 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQGQioUH8iai",
        "outputId": "b60a06c3-dbac-4a95-ce70-eb067ecce7e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator model params: 8.54 M\n",
            "Original FM model params: 65.61 M\n",
            "Online FM model params: 65.61 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "def train_fgm():\n",
        "\n",
        "    # 3) Define the optimizers and set up the main training loop\n",
        "    optimizer_online = torch.optim.Adam(Online_v_t.parameters(), lr=2e-5, betas=(0.0, 0.999))\n",
        "    optimizer_gen    = torch.optim.Adam(Generator.parameters(),  lr=2e-5, betas=(0.0, 0.999))\n",
        "\n",
        "    # Two separate scalers, one for each phase\n",
        "    scaler_online = GradScaler()\n",
        "    scaler_gen    = GradScaler()\n",
        "\n",
        "    flow_loss = UnconditionalFlowLoss(sigma_min=0.0)\n",
        "\n",
        "    n_epochs = 20000  # or however many iterations you want\n",
        "    log_interval = 50\n",
        "    save_interval = 1000\n",
        "\n",
        "    # Wrap your range(...) with tqdm(...) to get a progress bar\n",
        "\n",
        "    pbar = tqdm(range(n_epochs), desc=\"Distillation Training\")\n",
        "    for epoch in pbar:\n",
        "\n",
        "        ##################################################\n",
        "        # (a) Freeze Generator, train Online_v_t\n",
        "        ##################################################\n",
        "        for p in Generator.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in Online_v_t.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        Generator.eval()\n",
        "        Online_v_t.train()\n",
        "\n",
        "        optimizer_online.zero_grad()\n",
        "\n",
        "        # --- AMP context for Online_v_t phase ---\n",
        "        with autocast():\n",
        "            loss_flow_matching = flow_loss.loss_flow_matching(\n",
        "                Online_v_t=Online_v_t,\n",
        "                Pretrained_v_t=Pretrained_v_t,\n",
        "                Generator=Generator,\n",
        "                batch_size=8\n",
        "            )\n",
        "\n",
        "        # scaled backward, step, update\n",
        "        scaler_online.scale(loss_flow_matching).backward()\n",
        "        scaler_online.step(optimizer_online)\n",
        "        scaler_online.update()\n",
        "\n",
        "        loss_FM = loss_flow_matching.item()\n",
        "\n",
        "        ##################################################\n",
        "        # (b) Freeze Online_v_t, train Generator\n",
        "        ##################################################\n",
        "        for p in Generator.parameters():\n",
        "            p.requires_grad = True\n",
        "        for p in Online_v_t.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        Generator.train()\n",
        "        Online_v_t.eval()\n",
        "\n",
        "        optimizer_gen.zero_grad()\n",
        "\n",
        "        # --- AMP context for Generator phase ---\n",
        "        with autocast():\n",
        "            loss_generator_matching, image_gen = flow_loss.loss_generator_matching(\n",
        "                Online_v_t=Online_v_t,\n",
        "                Pretrained_v_t=Pretrained_v_t,\n",
        "                Generator=Generator,\n",
        "                batch_size=8\n",
        "            )\n",
        "\n",
        "        scaler_gen.scale(loss_generator_matching).backward()\n",
        "        scaler_gen.step(optimizer_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        loss_GM = loss_generator_matching.item()\n",
        "\n",
        "        pbar.set_description(f\"Distillation Training: \"\n",
        "                                 f\"Iter {epoch:05d} | \"\n",
        "                                 f\"Online FM Loss: {loss_FM:.6f} | \"\n",
        "                                 f\"Generator Matching Loss: {loss_GM:.6f}\")\n",
        "\n",
        "        # Log / plot periodically\n",
        "        if epoch % log_interval == 0:\n",
        "            Generator.eval()\n",
        "            print(f\"Iter {epoch:05d} | \"\n",
        "                f\"Online FM Loss: {loss_FM:.6f} | \"\n",
        "                f\"Generator Matching Loss: {loss_GM:.6f}\")\n",
        "\n",
        "            # Show a small sample from Generator vs the real flow's sample x_0\n",
        "            # with torch.no_grad():\n",
        "            #     z_show = torch.randn(8, 1, 28, 28, device=device)\n",
        "            #     t_span = torch.linspace(0, 1, 50, device=device)\n",
        "            #     #g_show = Generator(z_show).clamp(-1, 1)\n",
        "            #     traj = odeint(\n",
        "            #         Pretrained_v_t, z_show,\n",
        "            #         t_span,\n",
        "            #         method=\"euler\",\n",
        "            #         rtol=1e-5, atol=1e-5\n",
        "            #     )\n",
        "\n",
        "            #class_condition = torch.tensor([x for x in range(10)], device=device)\n",
        "\n",
        "            z = torch.randn(10, 3, 64, 64, device=device)\n",
        "            t_steps = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                traj = torchdiffeq.odeint(\n",
        "                    lambda _t, _x: Pretrained_v_t(_t, _x),\n",
        "                    z,\n",
        "                    t_steps,\n",
        "                    rtol=1e-5, atol=1e-5,\n",
        "                    method=\"euler\",\n",
        "                )\n",
        "\n",
        "            grid_gen = make_grid(traj[-1], nrow=5, value_range=(-1, 1))\n",
        "            grid_gen = (grid_gen.clamp(-1, 1) + 1) / 2.0  # Now in [0,1]\n",
        "            plt.figure(figsize=(6,6))\n",
        "            plt.imshow(grid_gen.permute(1,2,0).cpu().numpy())\n",
        "            plt.title(\"Ref final from Pretrained ODE (batch snippet)\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            grid_ref = make_grid(image_gen[:10].clamp(-1, 1), nrow=5, value_range=(-1,1))\n",
        "            grid_ref = (grid_ref.clamp(-1, 1) + 1) / 2.0  # Now in [0,1]\n",
        "            plt.figure(figsize=(6,6))\n",
        "            plt.imshow(grid_ref.permute(1,2,0).cpu().numpy())\n",
        "            plt.title(\"Generator single-step samples\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            # with torch.no_grad():\n",
        "            #     z_show = torch.randn(8, 1, 28, 28, device=device)\n",
        "            #     t_span = torch.linspace(0, 1, 50, device=device)\n",
        "            #     #g_show = Generator(z_show).clamp(-1, 1)\n",
        "            #     traj = odeint(\n",
        "            #         Online_v_t, z_show,\n",
        "            #         t_span,\n",
        "            #         method=\"euler\",\n",
        "            #         rtol=1e-5, atol=1e-5\n",
        "            #     )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                traj = torchdiffeq.odeint(\n",
        "                    lambda _t, _x: Online_v_t(_t, _x),\n",
        "                    z,\n",
        "                    t_steps,\n",
        "                    rtol=1e-5, atol=1e-5,\n",
        "                    method=\"euler\",\n",
        "                )\n",
        "\n",
        "            grid_ref = make_grid(traj[-1], nrow=5, value_range=(-1,1))\n",
        "            grid_ref = (grid_ref.clamp(-1, 1) + 1) / 2.0  # Now in [0,1]\n",
        "            plt.figure(figsize=(6,6))\n",
        "            plt.imshow(grid_ref.permute(1,2,0).cpu().numpy())\n",
        "            plt.title(\"Online model samples\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            Generator.train()\n",
        "\n",
        "        if epoch % save_interval == 0 and epoch != 0:\n",
        "            dataset_name = \"celeba\"\n",
        "\n",
        "            if os.path.exists(f\"./checkpoints/\") == False:\n",
        "                os.makedirs(f\"./checkpoints/\")\n",
        "\n",
        "            if os.path.exists(f\"./checkpoints/{dataset_name}/\") == False:\n",
        "                os.makedirs(f\"./checkpoints/{dataset_name}/\")\n",
        "\n",
        "            torch.save(Pretrained_v_t.state_dict(), f\"./checkpoints/{dataset_name}/Pretrained_v_t.pt\")\n",
        "            torch.save(Online_v_t.state_dict(), f\"./checkpoints/{dataset_name}/Online_v_t.pt\")\n",
        "            torch.save(Generator.state_dict(), f\"./checkpoints/{dataset_name}/Generator.pt\")"
      ],
      "metadata": {
        "id": "pzF2Iu5U8t1o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout"
      ],
      "metadata": {
        "id": "DIbu_bD_8zjV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with HiddenPrints():\n",
        "    train_fgm()\n",
        "\n",
        "# train_fgm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "cuLqDWNy80Nq",
        "outputId": "a797bee7-5afe-40cd-da40-e9decf1cf875"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-b83caf6f6d67>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_online = GradScaler()\n",
            "<ipython-input-21-b83caf6f6d67>:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_gen    = GradScaler()\n",
            "Distillation Training:   0%|          | 0/20000 [00:00<?, ?it/s]<ipython-input-21-b83caf6f6d67>:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "<ipython-input-21-b83caf6f6d67>:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Distillation Training:   0%|          | 0/20000 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 24.88 MiB is free. Process 2418701 has 39.52 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 236.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3c45af8cda83>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mHiddenPrints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_fgm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train_fgm()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-b83caf6f6d67>\u001b[0m in \u001b[0;36mtrain_fgm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# --- AMP context for Generator phase ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             loss_generator_matching, image_gen = flow_loss.loss_generator_matching(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mOnline_v_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOnline_v_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mPretrained_v_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPretrained_v_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-e9e019bb985d>\u001b[0m in \u001b[0;36mloss_generator_matching\u001b[0;34m(self, Online_v_t, Pretrained_v_t, Generator, batch_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mpre_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrained_v_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0monline_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOnline_v_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0monline_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x, y)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimestepBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0man\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m \u001b[0mx\u001b[0m \u001b[0mC\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/nn.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(func, inputs, params, flag)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGroupNorm32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 24.88 MiB is free. Process 2418701 has 39.52 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 236.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_samples(model,\n",
        "                     savedir=\"./results/\",\n",
        "                     step_=0,\n",
        "                     total_steps=2,\n",
        "                     net_=\"normal\",\n",
        "                     plot=True):\n",
        "    \"\"\"\n",
        "    Save and optionally plot 32 generated images (4 x 8) for a quick qualitative check.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # copy the trained model to avoid messing up BN stats (if any)\n",
        "    model_ = copy.deepcopy(model)\n",
        "\n",
        "    node_ = NeuralODE(model_, solver=\"euler\", sensitivity=\"adjoint\").to(device)\n",
        "    # sample random noise\n",
        "    z = torch.randn(1, 3, 64, 64, device=device)\n",
        "\n",
        "    # Evaluate trajectory from noise z from t=0 to t=1\n",
        "    t_span = torch.linspace(0, 1, total_steps, device=device)\n",
        "    traj = node_.trajectory(z, t_span)  # shape: [total_steps, 32, 3, 64, 64]\n",
        "    # final state\n",
        "    x_gen = traj[-1, :].clip(-1, 1)\n",
        "    x_gen = x_gen / 2 + 0.5  # move from [-1,1] to [0,1]\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(savedir, exist_ok=True)\n",
        "\n",
        "    # Save image grid\n",
        "    # save_image(\n",
        "    #     x_gen,\n",
        "    #     f\"{savedir}/{net_}_generated_FM_images_step_{step_}_total_{total_steps}.png\",\n",
        "    #     nrow=8\n",
        "    # )\n",
        "\n",
        "    if plot:\n",
        "        grid = make_grid(x_gen, nrow=8)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Generated Samples: {net_} | total_steps={total_steps-1}\")\n",
        "        plt.show()\n",
        "\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "v38htZX19UBQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_samples(model = ema_model, total_steps=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "euMg1WgJ_XTg",
        "outputId": "8830edf3-20e2-4f41-b6ad-05a8cd861394"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/GaParmar/clean-fid.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QXNLylCdWwT",
        "outputId": "dfde898a-a70a-491a-f1e1-5dbd35658ce3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/GaParmar/clean-fid.git\n",
            "  Cloning https://github.com/GaParmar/clean-fid.git to /tmp/pip-req-build-9n05i_sp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/GaParmar/clean-fid.git /tmp/pip-req-build-9n05i_sp\n",
            "  Resolved https://github.com/GaParmar/clean-fid.git to commit bd44693af04626963af76e94bdb1d4529a76bd11\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (4.67.1)\n",
            "Requirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from clean-fid==0.1.35) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid==0.1.35) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid==0.1.35) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid==0.1.35) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid==0.1.35) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid==0.1.35) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clean-fid==0.1.35) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clean-fid==0.1.35) (3.0.2)\n",
            "Building wheels for collected packages: clean-fid\n",
            "  Building wheel for clean-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clean-fid: filename=clean_fid-0.1.35-py3-none-any.whl size=26001 sha256=a2ce4ba064f2a3d92dd0fcfa5d06cda07c6f30a9d68d3c15c8348f3e829f3b85\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_fmiegfm/wheels/b2/44/89/45f075b1e99133e7011cdfb1799ae2bc35575dc7f428972a7d\n",
            "Successfully built clean-fid\n",
            "Installing collected packages: clean-fid\n",
            "Successfully installed clean-fid-0.1.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID calculations"
      ],
      "metadata": {
        "id": "6JGeDu95MPou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "import gc\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from torchvision.models import inception_v3\n",
        "from torchdiffeq import odeint\n",
        "from tqdm import tqdm  # <-- For progress bars\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "###################################################\n",
        "# Example UNet model (any network returning [-1,1])\n",
        "###################################################\n",
        "from torchcfm.models.unet.unet import UNetModelWrapper\n",
        "\n",
        "net_model = UNetModelWrapper(\n",
        "    dim=(3, 64, 64),\n",
        "    num_res_blocks=2,\n",
        "    num_channels=128,\n",
        "    channel_mult=[1, 2, 2, 4],\n",
        "    num_heads=4,\n",
        "    num_head_channels=64,\n",
        "    attention_resolutions=\"16\",\n",
        "    dropout=0.05,\n",
        ").to(device)\n",
        "\n",
        "ema_model = copy.deepcopy(net_model)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load(\"./checkpoints/fm_celeba_step_88000.pth\", map_location=device)\n",
        "state_dict_normal = checkpoint[\"net_model\"]\n",
        "state_dict_ema    = checkpoint[\"ema_model\"]\n",
        "\n",
        "net_model.load_state_dict(state_dict_normal)\n",
        "ema_model.load_state_dict(state_dict_ema)\n",
        "\n",
        "net_model.eval()\n",
        "ema_model.eval()\n",
        "\n",
        "###################################################\n",
        "# Dataloader for real CelebA images at 64×64\n",
        "###################################################\n",
        "def get_celeba_dataloader(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.CenterCrop(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # => [-1,1]\n",
        "    ])\n",
        "    celeba_train = datasets.CelebA(\n",
        "        root='./data',\n",
        "        split='train',\n",
        "        transform=transform,\n",
        "        download=False\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        celeba_train,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        drop_last=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return train_loader\n",
        "\n",
        "dataloader = get_celeba_dataloader(64)\n",
        "\n",
        "\n",
        "###################################################\n",
        "# FID Calculation Classes/Functions\n",
        "###################################################\n",
        "class FIDCalculator:\n",
        "    def __init__(self, device='cuda'):\n",
        "        self.device = device\n",
        "        # Load InceptionV3, remove final fc layer\n",
        "        self.inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "        self.inception_model.fc = torch.nn.Identity()  # remove classifier\n",
        "        self.inception_model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_activations(self, images: torch.Tensor):\n",
        "        \"\"\"\n",
        "        images: float Tensor in [0,1] (or [-1,1], but typically [0,1]) with shape (B,3,H,W).\n",
        "        We'll upsample to (299,299) for InceptionV3.\n",
        "        Returns a NumPy array of shape (B,2048) by default.\n",
        "        \"\"\"\n",
        "        # If images are in [-1,1], shift to [0,1] here (or do so beforehand).\n",
        "        # images = (images.clamp(-1,1) + 1)/2 if needed.\n",
        "\n",
        "        # Resize to Inception size\n",
        "        images = F.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "        feats = self.inception_model(images)\n",
        "        return feats.cpu().numpy()\n",
        "\n",
        "    def calculate_fid(self, real_features: np.ndarray, generated_features: np.ndarray):\n",
        "        mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "        mu2, sigma2 = np.mean(generated_features, axis=0), np.cov(generated_features, rowvar=False)\n",
        "\n",
        "        # Compute FID\n",
        "        ssdiff = np.sum((mu1 - mu2) ** 2)\n",
        "        covmean = linalg.sqrtm(sigma1.dot(sigma2))\n",
        "        if np.iscomplexobj(covmean):\n",
        "            covmean = covmean.real\n",
        "        fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "        return fid\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_images_for_fid(vnet, num_samples, device='cuda'):\n",
        "    \"\"\"\n",
        "    Generate images with ema_model from noise.\n",
        "    Return float Tensor in [0,1] shape (N,3,64,64).\n",
        "    \"\"\"\n",
        "    x = torch.randn(num_samples, 3, 64, 64, device=device)\n",
        "\n",
        "    t_span = torch.linspace(0, 1, 2, device=device)\n",
        "    traj = odeint(\n",
        "        vnet,\n",
        "        x,\n",
        "        t_span,\n",
        "        method=\"dopri5\",\n",
        "        rtol=1e-5,\n",
        "        atol=1e-5,\n",
        "    )\n",
        "    # Final state => shape (num_samples, 3, 64, 64) in [-1,1]\n",
        "    images = traj[-1]\n",
        "\n",
        "    # SHIFT from [-1,1] => [0,1]\n",
        "    images = (images.clamp(-1,1) + 1) / 2.0\n",
        "    return images  # float32 in [0,1]\n",
        "\n",
        "\n",
        "def calculate_fid_score(vnet, real_dataloader, num_samples=1000, device='cuda'):\n",
        "    \"\"\"\n",
        "    - Generate 'num_samples' fake images from the model\n",
        "    - Collect 'num_samples' real images from dataloader\n",
        "    - Compute Inception features, then compute FID\n",
        "    \"\"\"\n",
        "    fid_calculator = FIDCalculator(device)\n",
        "\n",
        "    # 1) Generate fake images\n",
        "    generated_images = generate_images_for_fid(vnet, num_samples, device=device)\n",
        "\n",
        "    # 2) Collect real images (with a TQDM progress bar)\n",
        "    real_images_list = []\n",
        "    collected = 0\n",
        "    for images, _ in tqdm(real_dataloader, desc=\"Collecting real images\"):\n",
        "        images = images.to(device)  # shape (B,3,64,64) in [-1,1]\n",
        "        real_images_list.append(images)\n",
        "        collected += images.size(0)\n",
        "        if collected >= num_samples:\n",
        "            break\n",
        "\n",
        "    real_images = torch.cat(real_images_list, dim=0)[:num_samples]  # (num_samples,3,64,64)\n",
        "\n",
        "    # 3) Extract Inception features\n",
        "    real_features = fid_calculator.get_activations(real_images)\n",
        "    generated_features = fid_calculator.get_activations(generated_images)\n",
        "\n",
        "    # 4) Compute FID\n",
        "    fid_value = fid_calculator.calculate_fid(real_features, generated_features)\n",
        "    return fid_value\n",
        "\n",
        "\n",
        "###################################################\n",
        "# Finally, usage\n",
        "###################################################\n",
        "def main():\n",
        "    # For a quick test with 1000 samples\n",
        "    fid_val = calculate_fid_score(ema_model, dataloader, num_samples=2000, device='cuda')\n",
        "    print(f\"FID Score: {fid_val}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "ZL-VYGLKixTp",
        "outputId": "03f474ed-9ed9-4cb1-cdde-bcb1e0349b21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c91a29337357>:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"./checkpoints/fm_celeba_step_88000.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.17 GiB is free. Process 2737491 has 38.38 GiB memory in use. Of the allocated memory 37.74 GiB is allocated by PyTorch, and 148.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c91a29337357>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-c91a29337357>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# For a quick test with 1000 samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mfid_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fid_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"FID Score: {fid_val}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c91a29337357>\u001b[0m in \u001b[0;36mcalculate_fid_score\u001b[0;34m(vnet, real_dataloader, num_samples, device)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# 1) Generate fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_images_for_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# 2) Collect real images (with a TQDM progress bar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c91a29337357>\u001b[0m in \u001b[0;36mgenerate_images_for_fid\u001b[0;34m(vnet, num_samples, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mt_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     traj = odeint(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mvnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_before_integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             first_step = _select_initial_step(self.func, t[0], self.y0, self.order - 1, self.rtol, self.atol,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x, y)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimestepBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0man\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m \u001b[0mx\u001b[0m \u001b[0mC\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/nn.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(func, inputs, params, flag)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/unet.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcfm/models/unet/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGroupNorm32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m     )\n\u001b[0;32m-> 2955\u001b[0;31m     return torch.group_norm(\n\u001b[0m\u001b[1;32m   2956\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.17 GiB is free. Process 2737491 has 38.38 GiB memory in use. Of the allocated memory 37.74 GiB is allocated by PyTorch, and 148.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}